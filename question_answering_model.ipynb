{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjCqQU-rfupK",
    "outputId": "553fbcbb-4767-4915-cfd2-c85eb46651d0"
   },
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration , TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxPNR8AMkO1a",
    "outputId": "027cee1f-e888-4606-c4dc-afee03a129ec"
   },
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"google-t5/t5-base\"\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.answers = self.data[\"answer\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "        context = self.context[idx]\n",
    "\n",
    "        # Tokenize the input (question and answer)\n",
    "        question_tokenized = self.tokenizer(question, context, padding=\"max_length\", max_length=self.max_length, \n",
    "                                            truncation=True, add_special_tokens=True)\n",
    "\n",
    "        # Get the tokenized answer\n",
    "        answer_tokenized = self.tokenizer(answer, context, padding=\"max_length\", max_length=128, \n",
    "                                            truncation=True, add_special_tokens=True)\n",
    "\n",
    "        labels = torch.tensor(answer_tokenized['input_ids'], dtype=torch.long)\n",
    "        labels[labels ==0] = -100\n",
    "\n",
    "        # Return the tokenized question-answer pair, attention mask, and the start/end positions\n",
    "        return {\n",
    "            'input_ids': torch.tensor(question_tokenized['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(question_tokenized['attention_mask'], dtype=torch.long),\n",
    "            'labels': labels,\n",
    "            'decoder_attention_mask': torch.tensor(answer_tokenized['attention_mask'], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4_1VeuBEktN",
    "outputId": "eddfcc3f-a3c5-45a3-88ed-e98cb1533afc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than half of the Makhzen's expenditures w...</td>\n",
       "      <td>Question: What were the consequences of the Ma...</td>\n",
       "      <td>Answer: The Makhzen's expenditures led to a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the 1890s, the French administration and mi...</td>\n",
       "      <td>Question: What were the main reasons behind th...</td>\n",
       "      <td>Answer: The main reasons behind the French ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morocco nominally was ruled by its sultan, the...</td>\n",
       "      <td>Question: What were the main reasons behind th...</td>\n",
       "      <td>Answer: The French saw Morocco as a strategic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General Hubert Lyautey wanted a more aggressiv...</td>\n",
       "      <td>Question: What was the outcome of the Algecira...</td>\n",
       "      <td>Answer: The Algeciras Conference of 1906 forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco experienced a famine from 1903 to 1907...</td>\n",
       "      <td>Question: What were the main causes of the Mor...</td>\n",
       "      <td>Answer: The Moroccan Famine from 1903 to 1907 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  More than half of the Makhzen's expenditures w...   \n",
       "1  In the 1890s, the French administration and mi...   \n",
       "2  Morocco nominally was ruled by its sultan, the...   \n",
       "3  General Hubert Lyautey wanted a more aggressiv...   \n",
       "4  Morocco experienced a famine from 1903 to 1907...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Question: What were the consequences of the Ma...   \n",
       "1  Question: What were the main reasons behind th...   \n",
       "2  Question: What were the main reasons behind th...   \n",
       "3  Question: What was the outcome of the Algecira...   \n",
       "4  Question: What were the main causes of the Mor...   \n",
       "\n",
       "                                              answer  \n",
       "0  Answer: The Makhzen's expenditures led to a de...  \n",
       "1  Answer: The main reasons behind the French ann...  \n",
       "2  Answer: The French saw Morocco as a strategic ...  \n",
       "3  Answer: The Algeciras Conference of 1906 forma...  \n",
       "4  Answer: The Moroccan Famine from 1903 to 1907 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./qa_dataset_en.csv', nrows=4000) # read only 4000 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than half of the Makhzen's expenditures w...</td>\n",
       "      <td>What were the consequences of the Makhzen's e...</td>\n",
       "      <td>The Makhzen's expenditures led to a deteriora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the 1890s, the French administration and mi...</td>\n",
       "      <td>What were the main reasons behind the French ...</td>\n",
       "      <td>The main reasons behind the French annexation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morocco nominally was ruled by its sultan, the...</td>\n",
       "      <td>What were the main reasons behind the French'...</td>\n",
       "      <td>The French saw Morocco as a strategic locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General Hubert Lyautey wanted a more aggressiv...</td>\n",
       "      <td>What was the outcome of the Algeciras Confere...</td>\n",
       "      <td>The Algeciras Conference of 1906 formalized F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco experienced a famine from 1903 to 1907...</td>\n",
       "      <td>What were the main causes of the Moroccan Fam...</td>\n",
       "      <td>The Moroccan Famine from 1903 to 1907 was cau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  More than half of the Makhzen's expenditures w...   \n",
       "1  In the 1890s, the French administration and mi...   \n",
       "2  Morocco nominally was ruled by its sultan, the...   \n",
       "3  General Hubert Lyautey wanted a more aggressiv...   \n",
       "4  Morocco experienced a famine from 1903 to 1907...   \n",
       "\n",
       "                                            question  \\\n",
       "0   What were the consequences of the Makhzen's e...   \n",
       "1   What were the main reasons behind the French ...   \n",
       "2   What were the main reasons behind the French'...   \n",
       "3   What was the outcome of the Algeciras Confere...   \n",
       "4   What were the main causes of the Moroccan Fam...   \n",
       "\n",
       "                                              answer  \n",
       "0   The Makhzen's expenditures led to a deteriora...  \n",
       "1   The main reasons behind the French annexation...  \n",
       "2   The French saw Morocco as a strategic locatio...  \n",
       "3   The Algeciras Conference of 1906 formalized F...  \n",
       "4   The Moroccan Famine from 1903 to 1907 was cau...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'] = df['question'].str.replace('Question:', '', regex=False) #removing 'Question:' keyword\n",
    "df['answer'] = df['answer'].str.replace('Answer:', '', regex=False) #removing 'Answer:' keyword\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  2892\n",
      "Val Data:  724\n"
     ]
    }
   ],
   "source": [
    "#data split\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "#print(train_data['question'])\n",
    "print(\"Train Data: \", len(train_data))\n",
    "print(\"Val Data: \", len(val_data))\n",
    "\n",
    "train_dataset = QADataset(train_data, tokenizer)\n",
    "val_dataset = QADataset(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',     \n",
    "    num_train_epochs=3,        \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,   \n",
    "    warmup_steps=100,               \n",
    "    weight_decay=0.03,\n",
    "    learning_rate=0.00001,\n",
    "    logging_steps=100,\n",
    "    eval_steps=300,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=300,\n",
    "    load_best_model_at_end=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1086' max='1086' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1086/1086 17:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.049377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.032908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1086, training_loss=0.2423902014561999, metrics={'train_runtime': 1021.6739, 'train_samples_per_second': 8.492, 'train_steps_per_second': 1.063, 'total_flos': 5283318658498560.0, 'train_loss': 0.2423902014561999, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_tokenizer\\\\tokenizer_config.json',\n",
       " 't5_tokenizer\\\\special_tokens_map.json',\n",
       " 't5_tokenizer\\\\spiece.model',\n",
       " 't5_tokenizer\\\\added_tokens.json',\n",
       " 't5_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"t5_model\")\n",
    "tokenizer.save_pretrained(\"t5_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5_model\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = tokenizer(question, context, max_length=512, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(model.device).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(model.device).unsqueeze(0)\n",
    "\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = tokenizer.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:\n",
    "        # Load the Bleu metric\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        score = bleu.compute(predictions=[predicted_answer], \n",
    "                            references=[ref_answer])\n",
    "    \n",
    "        print(\"Context: \", context)\n",
    "        print(\"Question: \", question)\n",
    "        print(\"\\nReference answer: \", ref_answer)\n",
    "        print(\"\\nPredicted answer: \", predicted_answer)\n",
    "        print(\"\\nBLEU Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Conda\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Tangier offers four types of education systems: Arabic, French, Spanish and English. Each offers classes starting from pre-Kindergarten up to the 12th grade, as for German in the three last years of high school. The Baccalauréat, or high school diploma are the diplomas offered after clearing the 12 grades.\n",
      "\n",
      "Question:   What are the four types of education systems offered in Tangier?\n",
      "\n",
      "Reference answer:   The four types of education systems offered in Tangier are Arabic, French, Spanish, and English. Each offers classes starting from pre-Kindergarten up to the 12th grade, with the Baccalauréat being the diploma offered after clearing the 12th grade.\n",
      "\n",
      "Predicted answer:  What are the four types of education systems offered in Tangier?\n",
      "\n",
      "BLEU Score:  {'google_bleu': 0.16470588235294117}\n"
     ]
    }
   ],
   "source": [
    "import evaluate  # Bleu\n",
    "context =  df.iloc[100]['context']\n",
    "question =  df.iloc[100]['question']\n",
    "answer =  df.iloc[100]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
