{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjCqQU-rfupK",
    "outputId": "553fbcbb-4767-4915-cfd2-c85eb46651d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Conda\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration , TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate  # Bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxPNR8AMkO1a",
    "outputId": "027cee1f-e888-4606-c4dc-afee03a129ec"
   },
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"google-t5/t5-base\"\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.answers = self.data[\"answer\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "        context = self.context[idx]\n",
    "\n",
    "        # Tokenize the input (question and answer)\n",
    "        question_tokenized = self.tokenizer(question, context, padding=\"max_length\", max_length=self.max_length, \n",
    "                                            truncation=True, add_special_tokens=True)\n",
    "\n",
    "        # Get the tokenized answer\n",
    "        answer_tokenized = self.tokenizer(answer, context, padding=\"max_length\", max_length=92, \n",
    "                                            truncation=True, add_special_tokens=True)\n",
    "\n",
    "        labels = torch.tensor(answer_tokenized['input_ids'], dtype=torch.long)\n",
    "        labels[labels ==0] = -100\n",
    "\n",
    "        # Return the tokenized question-answer pair, attention mask, and the start/end positions\n",
    "        return {\n",
    "            'input_ids': torch.tensor(question_tokenized['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(question_tokenized['attention_mask'], dtype=torch.long),\n",
    "            'labels': labels,\n",
    "            'decoder_attention_mask': torch.tensor(answer_tokenized['attention_mask'], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4_1VeuBEktN",
    "outputId": "eddfcc3f-a3c5-45a3-88ed-e98cb1533afc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than half of the Makhzen's expenditures w...</td>\n",
       "      <td>Question: What were the consequences of the Ma...</td>\n",
       "      <td>Answer: The Makhzen's expenditures led to a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the 1890s, the French administration and mi...</td>\n",
       "      <td>Question: What were the main reasons behind th...</td>\n",
       "      <td>Answer: The main reasons behind the French ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morocco nominally was ruled by its sultan, the...</td>\n",
       "      <td>Question: What were the main reasons behind th...</td>\n",
       "      <td>Answer: The French saw Morocco as a strategic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General Hubert Lyautey wanted a more aggressiv...</td>\n",
       "      <td>Question: What was the outcome of the Algecira...</td>\n",
       "      <td>Answer: The Algeciras Conference of 1906 forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco experienced a famine from 1903 to 1907...</td>\n",
       "      <td>Question: What were the main causes of the Mor...</td>\n",
       "      <td>Answer: The Moroccan Famine from 1903 to 1907 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  More than half of the Makhzen's expenditures w...   \n",
       "1  In the 1890s, the French administration and mi...   \n",
       "2  Morocco nominally was ruled by its sultan, the...   \n",
       "3  General Hubert Lyautey wanted a more aggressiv...   \n",
       "4  Morocco experienced a famine from 1903 to 1907...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Question: What were the consequences of the Ma...   \n",
       "1  Question: What were the main reasons behind th...   \n",
       "2  Question: What were the main reasons behind th...   \n",
       "3  Question: What was the outcome of the Algecira...   \n",
       "4  Question: What were the main causes of the Mor...   \n",
       "\n",
       "                                              answer  \n",
       "0  Answer: The Makhzen's expenditures led to a de...  \n",
       "1  Answer: The main reasons behind the French ann...  \n",
       "2  Answer: The French saw Morocco as a strategic ...  \n",
       "3  Answer: The Algeciras Conference of 1906 forma...  \n",
       "4  Answer: The Moroccan Famine from 1903 to 1907 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./qa_dataset_en.csv', nrows=4000) # read only 4000 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than half of the Makhzen's expenditures w...</td>\n",
       "      <td>What were the consequences of the Makhzen's e...</td>\n",
       "      <td>The Makhzen's expenditures led to a deteriora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the 1890s, the French administration and mi...</td>\n",
       "      <td>What were the main reasons behind the French ...</td>\n",
       "      <td>The main reasons behind the French annexation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morocco nominally was ruled by its sultan, the...</td>\n",
       "      <td>What were the main reasons behind the French'...</td>\n",
       "      <td>The French saw Morocco as a strategic locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General Hubert Lyautey wanted a more aggressiv...</td>\n",
       "      <td>What was the outcome of the Algeciras Confere...</td>\n",
       "      <td>The Algeciras Conference of 1906 formalized F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco experienced a famine from 1903 to 1907...</td>\n",
       "      <td>What were the main causes of the Moroccan Fam...</td>\n",
       "      <td>The Moroccan Famine from 1903 to 1907 was cau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  More than half of the Makhzen's expenditures w...   \n",
       "1  In the 1890s, the French administration and mi...   \n",
       "2  Morocco nominally was ruled by its sultan, the...   \n",
       "3  General Hubert Lyautey wanted a more aggressiv...   \n",
       "4  Morocco experienced a famine from 1903 to 1907...   \n",
       "\n",
       "                                            question  \\\n",
       "0   What were the consequences of the Makhzen's e...   \n",
       "1   What were the main reasons behind the French ...   \n",
       "2   What were the main reasons behind the French'...   \n",
       "3   What was the outcome of the Algeciras Confere...   \n",
       "4   What were the main causes of the Moroccan Fam...   \n",
       "\n",
       "                                              answer  \n",
       "0   The Makhzen's expenditures led to a deteriora...  \n",
       "1   The main reasons behind the French annexation...  \n",
       "2   The French saw Morocco as a strategic locatio...  \n",
       "3   The Algeciras Conference of 1906 formalized F...  \n",
       "4   The Moroccan Famine from 1903 to 1907 was cau...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'] = df['question'].str.replace('Question:', '', regex=False) #removing 'Question:' keyword\n",
    "df['answer'] = df['answer'].str.replace('Answer:', '', regex=False) #removing 'Answer:' keyword\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  2892\n",
      "Val Data:  724\n"
     ]
    }
   ],
   "source": [
    "#data split\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "#print(train_data['question'])\n",
    "print(\"Train Data: \", len(train_data))\n",
    "print(\"Val Data: \", len(val_data))\n",
    "\n",
    "train_dataset = QADataset(train_data, tokenizer)\n",
    "val_dataset = QADataset(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',     \n",
    "    num_train_epochs=5,        \n",
    "    per_device_train_batch_size=4,  \n",
    "    per_device_eval_batch_size=4,   \n",
    "    warmup_steps=100,               \n",
    "    weight_decay=0.03,\n",
    "    learning_rate=0.00001,\n",
    "    logging_steps=100,\n",
    "    eval_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3615' max='3615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3615/3615 21:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.119600</td>\n",
       "      <td>0.934206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.793696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.837100</td>\n",
       "      <td>0.740579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.800100</td>\n",
       "      <td>0.716435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.785900</td>\n",
       "      <td>0.701673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.707219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.684484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.678327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.672765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.716200</td>\n",
       "      <td>0.667945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.666398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>0.664309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.660949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.657963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.665500</td>\n",
       "      <td>0.656216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.654717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.654585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>0.654909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3615, training_loss=0.7641356102823387, metrics={'train_runtime': 1292.1619, 'train_samples_per_second': 11.191, 'train_steps_per_second': 2.798, 'total_flos': 8805531097497600.0, 'train_loss': 0.7641356102823387, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_tokenizer\\\\tokenizer_config.json',\n",
       " 't5_tokenizer\\\\special_tokens_map.json',\n",
       " 't5_tokenizer\\\\spiece.model',\n",
       " 't5_tokenizer\\\\added_tokens.json',\n",
       " 't5_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"t5_model\")\n",
    "tokenizer.save_pretrained(\"t5_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5_model\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = tokenizer(question, context, max_length=512, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(model.device).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(model.device).unsqueeze(0)\n",
    "\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = tokenizer.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:   \n",
    "        print(\"Context: \", context)\n",
    "        print(\"Question: \", question)\n",
    "        print(\"\\nReference answer: \", ref_answer)\n",
    "        print(\"\\nPredicted answer: \", predicted_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  The Greeks knew this town as Tingis and, with some modification, record the Berber legends of its founding. Supposedly Tinjis, daughter of Atlas and widow of Antaeus, slept with Hercules and bore him the son Syphax. After Tinjis' death, Syphax then founded the port and named it in her honour.[13] The gigantic skeleton and tomb of Antaeus were tourist attractions for ancient visitors.[13] The Caves of Hercules, where he supposedly rested on Cape Spartel during his labors, remain one today.[citation needed]\n",
      "\n",
      "Question:   Who was the daughter of Atlas and widow of Antaeus in Greek mythology?\n",
      "\n",
      "Reference answer:   The daughter of Atlas and widow of Antaeus in Greek mythology was Tinjis.\n",
      "\n",
      "Predicted answer:  The daughter of Atlas and widow of Antaeus in Greek mythology was Tinjis\n"
     ]
    }
   ],
   "source": [
    "context =  df.iloc[50]['context']\n",
    "question =  df.iloc[50]['question']\n",
    "answer =  df.iloc[50]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Things soon began to fall apart.  A nine-year plague enveloped Morocco in 1598–1607, weakening the country tremendously, and taking al-Mansur in 1603.[100]  His successor Abu Faris Abdallah was acclaimed in Marrakesh, but the jurists of Fez elevated his brother Zidan al-Nasir instead. Zidan managed to prevail and entered Marrakesh in 1609.  But now another brother, Muhammad al-Sheikh al-Ma'mun revolted in the north, and soon Zidan was reduced to Marrakesh.[101]  As Saadian power buckled, Morocco fell into anarchy and fragmented into smaller pieces for much of the next century.  Zidan was driven out of Marrakesh by a religious leader, the self-proclaimed mahdi Ahmed ibn Abi Mahalli in 1612, and was restored only in 1614 with the assistance of another religious leader, Yahya ibn Abdallah, a Sufi marabout from the High Atlas, who subsequently tried to exert his own power over the city from 1618 until his death in 1626.  Zidan somehow found the time and resources during all this to complete the Saadian Tombs at the Kasbah Mosque. However, there were not enough resources to complete a grand Saadian mosque begun by Ahmed al-Mansur, slated to be called the Jemaa al-Hana (\"Mosque of Prosperity\"); local people soon began to call the unfinished site the Jemaa el-Fnaa (Mosque of the Ruins), what would become the future central square of Marrakesh.[102]\n",
      "\n",
      "Question:   What was the name of the unfinished mosque built by Ahmed al-Mansur?\n",
      "\n",
      "Reference answer:   The name of the unfinished mosque built by Ahmed al-Mansur was Jemaa el-Fnaa (Mosque of the Ruins).\n",
      "\n",
      "Predicted answer:  The unfinished mosque was called the Jemaa el-Fnaa\n"
     ]
    }
   ],
   "source": [
    "context =  df.iloc[250]['context']\n",
    "question =  df.iloc[250]['question']\n",
    "answer =  df.iloc[250]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  \n",
      "Casablanca remained a modestly sized port, with a population reaching around 12,000 within a few years of the French conquest and arrival of French colonialists in the town, at first administrators within a sovereign sultanate, in 1906. By 1921, this was to rise to 110,000,[13] largely through the development of bidonvilles.\n",
      "Question:   What was the population of Casablanca during the French colonial period?\n",
      "\n",
      "Reference answer:   The population of Casablanca during the French colonial period was around 12,000 in 1906, which grew to 110,000 by 1921.\n",
      "\n",
      "Predicted answer:  Casablanca's population during the French colonial period was around 12,000 people.\n"
     ]
    }
   ],
   "source": [
    "context =  df.iloc[300]['context']\n",
    "question =  df.iloc[300]['question']\n",
    "answer =  df.iloc[300]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Rabat features a Mediterranean climate (Csa) with warm to hot, dry summers and mild, damp winters. Located along the Atlantic Ocean, Rabat has a mild, temperate climate, shifting from cool in winter to warm days in the summer months. The nights are always cool (or cold in winter, it can reach sub 0 °C (32 °F) sometimes), with daytime temperatures generally rising about 7–8 °C (13–14 °F). The winter highs typically reach only 17.2 °C (63.0 °F) in December–February. Summer daytime highs usually hover around 25 °C (77.0 °F), but may occasionally exceed 30 °C (86.0 °F), especially during heat waves. Summer nights are usually pleasant and cool, ranging between 11 °C (51.8 °F) and 19 °C (66.2 °F) and rarely exceeding 20 °C (68.0 °F). Rabat belongs to the sub-humid bioclimatic zone with an average annual precipitation of 560 mm (22 in).\n",
      "\n",
      "Question:   What is the climate like in Rabat, Morocco?\n",
      "\n",
      "Reference answer:   Rabat has a Mediterranean climate with warm to hot, dry summers and mild, damp winters. The nights are always cool, with temperatures ranging from cool to cold, and daytime temperatures generally rising about 7–8°C (13–14°F). The winter highs typically reach only 17.2°C (63.0°F) in December–February, while summer daytime highs usually hover around 25°C (77.0°F), but may occasionally exceed 30°C (86.0°F). Summer nights are usually pleasant and cool, ranging between 11°C (51.8°F) and 19°C (66.2°F), and rarely exceeding 20°C (68.0°F). Rabat belongs to the sub-humid bioclimatic zone with an average annual precipitation of 560mm (22in).\n",
      "\n",
      "Predicted answer:  Rabat features a Mediterranean climate (Csa) with warm to hot, dry summer\n"
     ]
    }
   ],
   "source": [
    "context =  df.iloc[165]['context']\n",
    "question =  df.iloc[165]['question']\n",
    "answer =  df.iloc[165]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  The history of Marrakesh, a city in southern Morocco, stretches back nearly a thousand years. The country of Morocco itself is named after it.\n",
      "\n",
      "Question:   What is the name of the country that Marrakesh is located in?\n",
      "\n",
      "Reference answer:   Morocco.\n",
      "\n",
      "Predicted answer:  The name of the country that Marrakesh is located in is Morocco.\n"
     ]
    }
   ],
   "source": [
    "context =  df.iloc[210]['context']\n",
    "question =  df.iloc[210]['question']\n",
    "answer =  df.iloc[210]['answer']\n",
    "\n",
    "predict_answer(context, question, answer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
